---
title: Type Classes from the Ground Up - Motivation
tags: scala
---

In this first post, we'll try to motivate the use of type classes by writing a simple CSV parser and attempting to
abstract over the type of data each row contains. By the time we're done, we should have a working, if fairly raw, type
class implementation. Future posts will work on refining that implementation.

<!--more-->

See the [introduction](/2015/11/21/tcgu-part-0.html) for more context and a table of content for the whole series.

# A simple CSV parser
CSV data, in its simplest expression, is just a set of lines (_rows_) composed of values (_cells_) separated by commas.
As a simple example, here's what a CSV file describing users might look like:

```
1,Nicolas,Rinaudo
2,Jessica,Jones
3,Matt,Murdock
```

Each row represents a complete user, and each cell in a given row describes a specific value for that user.

Our goal here is not to explore the various corner cases of CSV parsing, and we'll focus on a simple subset of that
problem: we'll assume that values cannot contain line breaks or commas. This means we can write a CSV parser as a simple
one-liner:

```scala
import scala.io.Source

def parseCsv(input: Source): Iterator[Array[String]] = input.getLines.map(_.split(","))
```

Note that we're knowingly ignoring two fairly important problems here. The first one is that this implementation is
leaky - coming up with a scenario in which streams (files, sockets...) are opened but never closed is trivial. The
second problem is that we're not dealing with errors, or at least not in an acceptable way: errors will cause exceptions
to be thrown when it would be better for them to be encoded in types.

While these two issues would not be acceptable in code that is meant to be executed in production systems, we're going
to ignore them here. Dealing with them would clutter up the code and is deemed detrimental to what we're trying to
achieve.



# Extracting interesting types
While our `parseCsv` function does indeed parse our subset of the CSV format, it's not terribly developer-friendly:
`Array[String]`, as a data type, is not great, unless your data is actually solely composed of strings (and even then,
exposing mutable data structures is rarely a good idea).

Consider the following data, declared as a string so we can attempt to parse it later:

```scala
scala> val input = "1,2,3\n4,5,6\n7,8,9"
input: String =
1,2,3
4,5,6
7,8,9
```

Parsing this as arrays of strings seems like a shame when the data is clearly composed of integers, but our current
`parseCsv` function can only return strings:

```scala
scala> parseCsv(Source.fromString(input)).toList
res0: List[Array[String]] = List(Array(1, 2, 3), Array(4, 5, 6), Array(7, 8, 9))
```

## Mapping on the return value
One way of turning that return value into the desired arrays of ints is simply to map on each array:

```scala
scala> parseCsv(Source.fromString(input)).map(_.map(_.toInt)).toList
res1: List[Array[Int]] = List(Array(1, 2, 3), Array(4, 5, 6), Array(7, 8, 9))
```

Note that we need to map twice: once to get into the iterator of rows, and once to get into each cell in a row.

We do end up with what we were after, an iterator on arrays of ints, but this solution is not... nice, for lack of a
better word. We'd much rather `parseCsv` did this for us, rather than having to manually map into the return value and
transform our data by hand.


## Letting `parseCsv` do the transformation
As a first step in that direction, let's rewrite `parseCsv` to accept a function that transforms each cell into the
desired type:

```scala
def parseCsv[A](input: Source)(f: String => A): Iterator[IndexedSeq[A]] = input.getLines.map(_.split(",").map(f))
```

Note that we also had to change the return type of our function: calling `map` on an `Array` doesn't yield another
`Array` but an [`ArraySeq`](http://www.scala-lang.org/api/current/index.html#scala.Tuple2). `ArraySeq` is not ideal, as
it exposes too much about the underlying implementation, but it also happens to be a subtype of
[`IndexedSeq`](http://www.scala-lang.org/api/current/index.html#scala.collection.immutable.IndexedSeq): a sequence with
guaranted constant-time or near constant-time access to its elements. We don't need to expose more than that, but the
constant random access time will come in handy later. It seems like a good choice of representation for rows, but we
might revisit that later if we need to.

We can now parse our matrix of ints in a slightly more pleasant way:

```scala
scala> parseCsv(Source.fromString(input))(_.toInt).toList
res2: List[IndexedSeq[Int]] = List(ArraySeq(1, 2, 3), ArraySeq(4, 5, 6), ArraySeq(7, 8, 9))
```

That is better, but still not great: we still have to pass our transformation function explicitly, and will probably
end up duplicating code all over the place when, really, there aren't many reasonable ways of extracting ints from
strings.

## Using implicit parameters
Scala has a mechanism for simplifying this:
[implicit parameters](http://www.scala-lang.org/files/archive/spec/2.11/07-implicits.html#implicit-parameters). We'll
first explain what these are, then have a look at how they can be used for `parseCsv`.


### Implicit parameters
If a function has a parameter that is marked as implicit, and a value of the same type this is also marked as implicit
can be found, there is no need to pass that value explicitly: the compiler will do it for us.

Note that I'm glossing over some complexity here - where does the compiler look for such values? what happens when more
than one is found? what are the precedence rules, if any? These are important questions, and we will eventually need to
answer them, but it's not crucial to do so just now and would detract from this post's main point.

To give a simple, somewhat nonsensical example of an implicit parameter:

```scala
scala> implicit val a: Int = 2
a: Int = 2

scala> def printInt(implicit i: Int): Unit = println(i)
printInt: (implicit i: Int)Unit

scala> printInt
2
```

`a` is marked as implicit and `printInt` expects an implicit parameter of the same type: this allows us to call
`printInt` without an argument and let the compiler work out how to fill in the blanks.

There's a small twist to the implicit resolution mechanism that we won't need now, but will be terribly helpful later:
if no value of the expected type is found, but a _function_ capable of generating values of that type is marked as
implicit, then it will be used. And this is done recursively: such functions can expect implicit parameters, which might
come from implicit functions, which...

Here's our simple example, reworked to demonstrate this behaviour:

```scala
scala> implicit val a: (Int, Int) = (3, 4)
a: (Int, Int) = (3,4)

scala> implicit def firstInt[A](implicit tuple: (Int, A)): Int = tuple._1
firstInt: [A](implicit tuple: (Int, A))Int

scala> def printInt(implicit i: Int): Unit = println(i)
printInt: (implicit i: Int)Unit

scala> printInt
3
```

`printInt` is looking for an implicit value of type `Int`. There is none, but `firstInt` is implicit and has a return
value of type `Int`: the compiler will check whether it can be called. `firstInt` needs an implicit value of type
`(Int, ?)` to exist, and `a` matches: this allows us to generate a value of type `Int` implicitly, which can then be
used by `printInt`.

### Transformation function as an implicit parameter
Now that we know what an implicit parameter is, we can apply that knowledge to our use case: we could have `parseCsv`
expect the parsing function as an implicit parameter, and let callers make sure the right implicit value is available.

It could look something like:

```scala
def parseCsv[A](input: Source)(implicit f: String => A): Iterator[IndexedSeq[A]] =
  input.getLines.map(_.split(",").map(f))

implicit val strToInt: String => Int = Integer.parseInt
```

And we can now call `parseCsv` very simply:

```scala
scala> parseCsv[Int](Source.fromString(input)).toList
res5: List[IndexedSeq[Int]] = List(ArraySeq(1, 2, 3), ArraySeq(4, 5, 6), ArraySeq(7, 8, 9))
```

This `parseCsv[Int]...` syntax might be unfamiliar: we're passing an explicit type parameter to `parseCsv`.
The compiler generally manages to work out the value of a function's type parameters from the types of the actual
arguments, but in this specific case, the type parameter describes the return value. There is no context to decide what
we're expecting, and we need to be explicit about it.

Note that something almost magical happened here: we have been able to retrofit the `Int` class with the ability to be
decoded as a CSV cell, and we have done so without ever touching its code, or wrapping it in a class whose sole
purpose is to add a `parseAsCsv` method to `Int`. It's almost as if we didn't need inheritance...


## Finally: type classes
There's still a pretty major flaw in our implementation: declaring implicit functions has undesirable side-effects. In
our example, we've just told the Scala compiler how to implicitly turn all strings into ints - without meaning to, we've
plugged in to the implicit conversion mechanism. This means that our `strToInt` function will get called whenever the
compiler finds a string where it expected an int. For example:

```scala
scala> "123": Int
res6: Int = 123
```

This is obviously not desirable and can lead to all sorts of problems. One important rule when using implicit parameters
is to use types that are as specific as possible, so that our values do not get picked by other bits of code looking for
implicits.

So, rather than use a generic function, we should declare a much more specific trait, `CellDecoder`:

```scala
trait CellDecoder[T] {
  def decode(s: String): T
}
```

It looks rather a lot like a `String => T`, but isn't and will not be picked up by implicit resolution when it should
not. An added benefit is that we can tack on all sorts of helper functions to the trait - `CellDecoder` is crying out
for a `map` method, for example.

We can now rewrite `parseCsv` to expect an instance of `CellDecoder` rather than a function, and declare a
`CellDecoder[Int]`:

```scala
def parseCsv[A](input: Source)(implicit da: CellDecoder[A]): Iterator[IndexedSeq[A]] =
  input.getLines.map(_.split(",").map(da.decode))

implicit val intDecoder: CellDecoder[Int] = new CellDecoder[Int] {
  override def decode(s: String) = s.toInt
}
```

And we can still call `parseCsv` just as we did before:

```scala
scala> parseCsv[Int](Source.fromString(input)).toList
res7: List[IndexedSeq[Int]] = List(ArraySeq(1, 2, 3), ArraySeq(4, 5, 6), ArraySeq(7, 8, 9))
```

And with that, we have just invented type classes: a construct that allows us to add behaviour to existing types without
needing to modify them.

`CellDecoder` allows us to retrofit any type (for which it makes sense) with the ability to be excracted from a CSV
cell. Our `CellDecoder[Int]`, for example, has added this feature to ints, even though `Int` is marked as final.


# What next?
While it looks like we've dealt with the problem we set out to solve, this is at best an incomplete solution. We can
parse CSV rows whose cells are all of the same type, but that is hardly sufficient - what about data where rows contain
cells of different types? What if we want to parse rows as specific business types rather than generic sequences?

In the [next post](/2015/11/23/tcgu-part-2.html), we'll see how to deal with these problems, and the incredibly useful
way in which simple type class instances combine implicitly to generate much more complex ones.
